# app.py - Streamlit + LangChain ì˜ˆì œ
import os

import streamlit as st
from dotenv import load_dotenv
from langchain_community.chat_message_histories import StreamlitChatMessageHistory
from langchain_openai import ChatOpenAI
from langchain.schema import HumanMessage

load_dotenv()

# ì œëª© ë° ì„¤ëª…
st.title("ğŸš€ Hello, AWS EC2 from Streamlit with LangChain!")
st.write("AWS EC2ì—ì„œ Streamlitê³¼ LangChainì„ ì´ìš©í•œ AI ì±—ë´‡ì…ë‹ˆë‹¤. ğŸ‰")

# Chat History ì´ˆê¸°í™”
history = StreamlitChatMessageHistory()

# ì´ì „ ë©”ì‹œì§€ ì¶œë ¥
for message in history.messages:
    with st.chat_message(message.type):
        st.markdown(message.content)

# Chat Input & Chat Message ì‚¬ìš©
prompt = st.chat_input("What's up?")

if prompt:
    # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶œë ¥
    with st.chat_message("user"):
        history.add_user_message(prompt)
        st.markdown(prompt)

    # AI ì‘ë‹µ ì¶œë ¥
    with st.chat_message("assistant"):
        chat = ChatOpenAI(
            model_name=os.getenv("OPENAI_API_MODEL"),
            temperature=float(os.getenv("OPENAI_API_TEMPERATURE", 0.5)),
            max_tokens=500
        )
        messages = [HumanMessage(content=prompt)]

        response = chat.invoke(messages)  # AIMessage ê°ì²´ ë°˜í™˜
        response_content = response.content  # ë¬¸ìì—´ë¡œ ë³€í™˜

        history.add_ai_message(response_content)  # ë¬¸ìì—´ë§Œ ì €ì¥
        st.markdown(response.content)  # í™”ë©´ì— í‘œì‹œ
